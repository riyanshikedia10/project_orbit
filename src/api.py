from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
from typing import List, Dict, Optional
import json
from pathlib import Path
import os
import dotenv
from google.cloud import storage
from google.api_core.exceptions import NotFound
from google.oauth2 import service_account
from rag_pipeline import generate_dashboard, retrieve_context, load_system_prompt
from openai import OpenAI
from services.embeddings import Embeddings
from structured_extraction import extract_company_payload
from urllib.parse import urlparse


dotenv.load_dotenv()

# Initialize FastAPI app
app = FastAPI(
    title="Project Orbit API",
    description="PE Dashboard Factory API for Forbes AI 50 Companies",
    version="0.1.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# Initialize clients
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
embeddings_client = Embeddings()

storage_client = None



def get_storage_client():
    """Get or create GCS storage client"""
    global storage_client
    
    # If already initialized, return it
    if storage_client is not None:
        return storage_client
    
    # Check if we need GCS (production mode)
    bucket_name = os.getenv("GCS_BUCKET_NAME")
    if not bucket_name:
        # Local development - don't initialize
        print("GCS_BUCKET_NAME not set, skipping GCS client initialization")
        return None
    
    # Production mode - MUST initialize successfully
    print(f"Initializing GCS client for bucket: {bucket_name}")
    try:
        project_id = os.getenv("PROJECT_ID")
        PROJECT_ROOT = Path(__file__).parent.parent
        credentials_path = PROJECT_ROOT / "config" / "gcp.json"
        
        # Try to use credentials file if it exists (local development)
        if credentials_path.exists():
            from google.oauth2 import service_account
            credentials = service_account.Credentials.from_service_account_file(
                str(credentials_path)
            )
            storage_client = storage.Client(project=project_id, credentials=credentials)
            print(f"GCS client initialized with credentials from {credentials_path}")
        else:
            # Use Application Default Credentials (production/Cloud Run)
            # Cloud Run automatically provides credentials via the service account
            storage_client = storage.Client(project=project_id)
            print("GCS client initialized with Application Default Credentials (production mode)")
        
        print("GCS client initialized successfully")
        return storage_client
    except Exception as e:
        error_msg = str(e)
        print(f"ERROR: Failed to initialize GCS client: {error_msg}")
        
        # In production, this is a critical error - raise it
        raise HTTPException(
            status_code=500,
            detail=f"GCS client initialization failed. This is required when GCS_BUCKET_NAME is set. "
                   f"Error: {error_msg}. "
                   f"Check that the Cloud Run service account has 'Storage Object Viewer' role. "
                   f"Verify that Application Default Credentials are configured correctly."
        )
        
# Paths
PROJECT_ROOT = Path(__file__).parent.parent
SEED_FILE = PROJECT_ROOT / "data" / "forbes_ai50_seed.json"
PAYLOADS_DIR = PROJECT_ROOT / "data" / "payloads"


# ============================================================================
# Pydantic Models
# ============================================================================

class CompanyRequest(BaseModel):
    """Request model for company name"""
    company_name: str = Field(..., description="Name of the company (e.g., 'Abridge', 'Anthropic')")

class RAGSearchRequest(BaseModel):
    """Request model for RAG search"""
    company_name: str = Field(..., description="Name of the company to search")
    top_k: Optional[int] = Field(10, ge=1, le=50, description="Number of top results to return")

class DashboardResponse(BaseModel):
    """Response model for dashboard generation"""
    company_name: str
    dashboard: str
    pipeline_type: str  # "rag" or "structured"

class RAGSearchResponse(BaseModel):
    """Response model for RAG search"""
    company_name: str
    results: List[Dict]
    total_results: int

class CompanyInfo(BaseModel):
    """Company information model"""
    company_name: str
    website: str
    linkedin: str
    hq_city: str
    hq_country: str
    category: str

def load_companies() -> List[Dict]:
    """Load companies from seed file (local development)"""
    try:
        with open(SEED_FILE, 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="Company seed file not found")
    except json.JSONDecodeError:
        raise HTTPException(status_code=500, detail="Invalid JSON in seed file")

def load_companies_from_gcs() -> List[Dict]:
    """Load companies from GCS bucket (production)"""
    try:
        # Check if GCS_BUCKET_NAME is set
        bucket_name = os.getenv("GCS_BUCKET_NAME")
        if not bucket_name:
            raise HTTPException(
                status_code=500, 
                detail="GCS_BUCKET_NAME environment variable is not set"
            )
        
        # Initialize GCS client lazily
        client = get_storage_client()
        if not client:
            raise HTTPException(
                status_code=500,
                detail="GCS client is not initialized. Check service account permissions and ensure GCS_BUCKET_NAME is set."
            )
        
        # Get the file path (remove leading slash if present)
        file_path = os.getenv("GCS_SEED_FILE_PATH", "seed/forbes_ai50_seed.json")
        if file_path.startswith('/'):
            file_path = file_path[1:]
        
        # Get the bucket and blob
        bucket = client.bucket(bucket_name)
        blob = bucket.blob(file_path)
        
        # Check if blob exists
        if not blob.exists():
            raise HTTPException(
                status_code=404,
                detail=f"File not found in GCS: gs://{bucket_name}/{file_path}"
            )
        
        # Download and parse JSON
        content = blob.download_as_text()
        companies = json.loads(content)
        
        # Validate it's a list
        if not isinstance(companies, list):
            raise HTTPException(
                status_code=500,
                detail="Invalid data format: expected a list of companies"
            )
        
        return companies
        
    except Exception as e:
        # Check if it's a NotFound exception by checking error message/type
        error_str = str(e).lower()
        if 'not found' in error_str or '404' in error_str:
            raise HTTPException(
                status_code=404,
                detail=f"GCS bucket or file not found: gs://{bucket_name}/{file_path}"
            )
        elif isinstance(e, HTTPException):
            # Re-raise HTTP exceptions
            raise
        elif isinstance(e, json.JSONDecodeError):
            raise HTTPException(
                status_code=500,
                detail=f"Invalid JSON in GCS file: {str(e)}"
            )
        else:
            raise HTTPException(
                status_code=500,
                detail=f"Failed to load companies from GCS: {str(e)}"
            )
def get_company_id_from_name(company_name: str) -> str:
    """Get company_id from company name by looking up website"""
    try:
        # Load companies (same logic as get_companies endpoint)
        if os.getenv("GCS_BUCKET_NAME"):
            companies = load_companies_from_gcs()
        else:
            companies = load_companies()
        
        # Find company by name (case-insensitive)
        company = None
        for c in companies:
            if c.get("company_name", "").lower() == company_name.lower():
                company = c
                break
        
        if not company:
            raise HTTPException(
                status_code=404,
                detail=f"Company '{company_name}' not found in seed file"
            )
        
        # Extract company_id from website domain
        website = company.get("website", "")
        if not website:
            raise HTTPException(
                status_code=400,
                detail=f"Company '{company_name}' has no website URL"
            )
        
        domain = urlparse(website).netloc
        company_id = domain.replace("www.", "").split(".")[0]
        return company_id.lower()
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Failed to get company_id: {str(e)}"
        )


# ============================================================================
# API Endpoints
# ============================================================================

@app.get("/", tags=["Root"])
async def root():
    """Root endpoint"""
    return {
        "message": "Project Orbit API - PE Dashboard Factory",
        "version": "0.1.0",
        "endpoints": {
            "companies": "/companies",
            "dashboard_rag": "/dashboard/rag",
            "dashboard_structured": "/dashboard/structured",
        }
    }

@app.get("/companies", response_model=List[CompanyInfo], tags=["Companies"])
async def get_companies():
    """
    Get list of all Forbes AI 50 companies.
    
    Returns a list of all companies with their basic information.
    """
    try:
        # Check if we should use GCS (production) or local file (development)
        if os.getenv("GCS_BUCKET_NAME"):
            companies = load_companies_from_gcs()
        else:
            companies = load_companies()
        
        return [CompanyInfo(**company) for company in companies]
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to load companies: {str(e)}")

@app.post("/dashboard/rag", response_model=DashboardResponse, tags=["Dashboard"])
async def generate_rag_dashboard(request: CompanyRequest):
    """
    Generate an investor-facing diligence dashboard using RAG pipeline.
    
    This endpoint implements Lab 7:
    - Retrieves top-k context from vector DB
    - Calls LLM with dashboard prompt
    - Returns markdown dashboard with all 8 required sections
    
    The dashboard is generated from unstructured data stored in the vector database.
    """
    try:
        print(f"Generating dashboard for {request.company_name}")
        dashboard = generate_dashboard(request.company_name)
        print(dashboard)
        return DashboardResponse(
            company_name=request.company_name,
            dashboard=dashboard,
            pipeline_type="rag"
        )
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Failed to generate RAG dashboard: {str(e)}"
        )


# Structured dashboard generation endpoint
@app.post("/dashboard/structured", response_model=DashboardResponse, tags=["Dashboard"])
async def generate_structured_dashboard(request: CompanyRequest):
    """
    Generate an investor-facing diligence dashboard using structured extraction pipeline.
    
    This endpoint:
    - Loads pre-generated payload from data/payloads/<company_id>.json (or GCS)
    - If payload exists: Calls LLM with structured payload to generate dashboard
    - If payload doesn't exist: Returns "Not disclosed" dashboard without LLM call
    - Returns markdown dashboard with all 8 required sections
    """
    try:
        print(f"Generating structured dashboard for {request.company_name}")
        
        # Step 1: Get company_id from company_name
        company_id = get_company_id_from_name(request.company_name)
        print(f"Company ID: {company_id}")
        
        # Step 2: Try to load payload from file/GCS
        payload = None
        bucket_name = os.getenv("GCS_BUCKET_NAME")
        use_gcs = bucket_name is not None and get_storage_client() is not None
        
        if use_gcs:
            # Try to load from GCS
            payload_path = f"payloads/{company_id}.json"
            print(f"Loading payload from GCS: gs://{bucket_name}/{payload_path}")
            
            client = get_storage_client()
            if client:
                try:
                    bucket = client.bucket(bucket_name)
                    blob = bucket.blob(payload_path)
                    
                    if blob.exists():
                        content = blob.download_as_text()
                        payload_data = json.loads(content)
                        # Convert dict to Payload object
                        from models import Payload
                        payload = Payload(**payload_data)
                        print(f"✅ Loaded payload from GCS")
                    else:
                        print(f"⚠️  Payload not found in GCS: {payload_path}")
                except Exception as e:
                    print(f"⚠️  Failed to load payload from GCS: {e}")
        else:
            # Try to load from local filesystem
            payload_path = PAYLOADS_DIR / f"{company_id}.json"
            print(f"Loading payload from local: {payload_path}")
            
            if payload_path.exists():
                try:
                    with open(payload_path, 'r') as f:
                        payload_data = json.load(f)
                    from models import Payload
                    payload = Payload(**payload_data)
                    print(f"✅ Loaded payload from local file")
                except Exception as e:
                    print(f"⚠️  Failed to load payload from local file: {e}")
            else:
                print(f"⚠️  Payload file not found: {payload_path}")
        
        # Step 3: If no payload found, return "Not disclosed" dashboard
        if payload is None:
            print(f"⚠️  No payload found for {request.company_name}")
            print(f"   Returning 'Not disclosed' dashboard without LLM call")
            expected_path = f"gs://{bucket_name}/payloads/{company_id}.json" if use_gcs else str(PAYLOADS_DIR / f"{company_id}.json")
            # Build minimal dashboard with company name only
            dashboard = f"""## Company Overview

Legal Name: Not disclosed
Website: Not disclosed
Headquarters: Not disclosed
Categories: Not disclosed
Total Raised: Not disclosed
Last Round Name: Not disclosed
Last Round Date: Not disclosed
Founded Year: Not disclosed

## Business Model and GTM

Not disclosed.

## Funding & Investor Profile

Not disclosed.

## Growth Momentum

Not disclosed.

## Visibility & Market Sentiment

Not disclosed.

## Risks and Challenges

Not disclosed.

## Outlook

Not disclosed.

## Disclosure Gaps

## Disclosure Gaps

No payload found. Expected payload at: {expected_path}
Please ensure the payload has been generated and stored."""
            
            return DashboardResponse(
                company_name=request.company_name,
                dashboard=dashboard,
                pipeline_type="structured"
            )
        
        # Step 4: Payload exists - check if it has scraped data
        has_scraped_data = (
            len(payload.events) > 0 or 
            len(payload.products) > 0 or 
            len(payload.leadership) > 0
        )
        
        if not has_scraped_data:
            # Payload exists but has no scraped data - return "Not disclosed" dashboard
            print(f"⚠️  Payload found but no scraped data for {request.company_name}")
            print(f"   Returning 'Not disclosed' dashboard without LLM call to prevent hallucination")
            
            company = payload.company_record
            dashboard = f"""## Company Overview

Legal Name: {company.legal_name or 'Not disclosed'}
Website: {company.website or 'Not disclosed'}
Headquarters: {company.hq_city or 'Not disclosed'}, {company.hq_state or ''} {company.hq_country or 'Not disclosed'}
Categories: {', '.join(company.categories) if company.categories else 'Not disclosed'}
Total Raised: {f"${company.total_raised_usd:,.0f}" if company.total_raised_usd else "Not disclosed"}
Last Round Name: {company.last_round_name or 'Not disclosed'}
Last Round Date: {company.last_round_date or 'Not disclosed'}
Founded Year: {company.founded_year or 'Not disclosed'}


No scraped data found in payload. Expected scraped data at: gs://{os.getenv('GCS_BUCKET_NAME', 'bucket')}/raw/{company_id}/initial_pull/
Please ensure the scheduler has scraped and uploaded data to GCS bucket."""
            
            return DashboardResponse(
                company_name=request.company_name,
                dashboard=dashboard,
                pipeline_type="structured"
            )
        
        # Step 5: Payload exists and has scraped data - generate dashboard with LLM
        print(f"✅ Payload found with scraped data - generating dashboard with LLM")
        
        # Convert payload to JSON for LLM
        payload_json = json.dumps(payload.model_dump(), indent=2, default=str)
        
        # Load system prompt (same as RAG)
        system_prompt = load_system_prompt()
        
        # Create user prompt with structured payload
        user_prompt = f"""Generate a comprehensive investor-facing diligence dashboard for {request.company_name}.

Use ONLY the information provided in the Payload below. If something is unknown or not disclosed, literally say "Not disclosed."

If a claim is marketing, attribute it: "The company states ..."

Never include personal emails or phone numbers.

Always include the final section "## Disclosure Gaps".
Payload:
{payload_json}

IMPORTANT: You MUST include all 8 sections in this exact order:
1. ## Company Overview
2. ## Business Model and GTM
3. ## Funding & Investor Profile
4. ## Growth Momentum
5. ## Visibility & Market Sentiment
6. ## Risks and Challenges
7. ## Outlook
8. ## Disclosure Gaps

Do not include any sections beyond these 8. If you cannot find information for a section, write "Not disclosed." for that section."""
        # Call LLM with retry logic (same as RAG)
        max_retries = 3
        dashboard = None
        
        for attempt in range(max_retries):
            try:
                response = openai_client.chat.completions.create(
                    model=os.getenv("LLM_MODEL", "gpt-4o-mini"),
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.3,
                    max_tokens=4000
                )
                
                dashboard = response.choices[0].message.content
                
                # Validate that all required sections are present
                required_sections = [
                    "## Company Overview",
                    "## Business Model and GTM",
                    "## Funding & Investor Profile",
                    "## Growth Momentum",
                    "## Visibility & Market Sentiment",
                    "## Risks and Challenges",
                    "## Outlook",
                    "## Disclosure Gaps"
                ]
                
                missing_sections = []
                for section in required_sections:
                    if section not in dashboard:
                        missing_sections.append(section)
                
                if missing_sections:
                    # If sections are missing, add them with "Not disclosed."
                    dashboard += "\n\n"
                    for section in missing_sections:
                        dashboard += f"\n{section}\n\nNot disclosed.\n"
                
                break  # Success, exit retry loop
                
            except Exception as e:
                if attempt == max_retries - 1:
                    raise Exception(f"Failed to generate dashboard after {max_retries} attempts: {str(e)}")
                continue
        
        if not dashboard:
            raise Exception("Failed to generate dashboard")
        
        print(f"Dashboard generated successfully for {request.company_name}")
        
        return DashboardResponse(
            company_name=request.company_name,
            dashboard=dashboard,
            pipeline_type="structured"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Failed to generate structured dashboard: {str(e)}"
        )
# ============================================================================
# Health Check
# ============================================================================

@app.get("/health", tags=["Health"])
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "service": "Project Orbit API"
    }